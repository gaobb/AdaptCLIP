
# AdaptCLIP

[![HuggingFace Space](https://img.shields.io/badge/ðŸ¤—-HuggingFace%20Space-cyan.svg)](https://huggingface.co/spaces/csgaobb/AdaptCLIP)

> Official PyTorch Implementation of [AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection](https://www.arxiv.org/pdf/2505.09926), 2025.



## Introduction 
Universal visual anomaly detection aims to identify anomalies from novel or unseen vision domains without additional fine-tuning, which is critical in open scenarios. 

- Adaptive visual and textual representations should be learned alternately rather than jointly.
- Comparative learning should incorporate contextual and aligned residual features rather than relying solely on residual features.

## ToDo List
- [x] release pre-trained AdaptCLIP models
- [x] deploy online AdaptCLIP Demo on HuggingFace
- [x] open testing code
- [x] open training code




